{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xianyummy/C-projects/blob/main/image_classification_with_vision_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PX_6DdScf0o"
      },
      "source": [
        "This notebook comes from this tutorial [Image classification with Vision Transformer](https://keras.io/examples/vision/image_classification_with_vision_transformer/). I have only modified the hyperparameters to train the underlying model on the CIFAR-10 dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsNe8FAPu5zU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0OkBbbbu80d",
        "outputId": "789112d1-83d4-4324-c511-8119b4998421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n",
            "Found existing installation: tensorflow 2.17.1\n",
            "Uninstalling tensorflow-2.17.1:\n",
            "  Successfully uninstalled tensorflow-2.17.1\n",
            "Found existing installation: tensorflow-addons 0.23.0\n",
            "Uninstalling tensorflow-addons-0.23.0:\n",
            "  Successfully uninstalled tensorflow-addons-0.23.0\n",
            "Collecting tensorflow==2.15.0\n",
            "  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n",
            "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.69.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, ml-dtypes, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.0\n",
            "    Uninstalling wrapt-1.17.0:\n",
            "      Successfully uninstalled wrapt-1.17.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorstore 0.1.71 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 wrapt-1.14.1\n",
            "Collecting tensorflow-addons\n",
            "  Using cached tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.2)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Using cached tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U tensorflow-addons\n",
        "!pip uninstall tensorflow tensorflow-addons -y\n",
        "!pip install tensorflow==2.15.0\n",
        "!pip install tensorflow-addons\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-WQLr-Rcu5zV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779dbd52-30c6-44b0-90c4-74c9b428f15c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_DrbSiRu5zV"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA2smPSxu5zV",
        "outputId": "5e89d231-a491-4c08-acbe-bf6df7182c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n",
            "Unique labels in y_train: [0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ],
      "source": [
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
        "print(f\"Unique labels in y_train: {np.unique(y_train)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-JvZqfOu5zV"
      },
      "source": [
        "## Configure the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "K902Ap-4u5zV"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 64\n",
        "num_epochs = 200\n",
        "image_size = 32\n",
        "patch_size = 4  # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 48\n",
        "num_heads = 2\n",
        "transformer_units = [\n",
        "    projection_dim,\n",
        "    projection_dim,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers = 2\n",
        "mlp_head_units = [projection_dim * 4, projection_dim * 2]  # Size of the dense layers of the final classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUumYGytu5zW"
      },
      "source": [
        "## Use data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RfsN3KJXu5zW"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.Rescaling(scale=1./255),\n",
        "        layers.experimental.preprocessing.RandomCrop(image_size, image_size),\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\")\n",
        "    ],\n",
        "    name=\"data_augmentation\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXwEcxHbu5zW"
      },
      "source": [
        "## Implement multilayer perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LxMwV3tGu5zW"
      },
      "outputs": [],
      "source": [
        "\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNJGuApRu5zW"
      },
      "source": [
        "## Implement patch creation as a layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "obAurvIfu5zW"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size,**kwargs):\n",
        "        super(Patches, self).__init__(**kwargs)\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'patch_size': self.patch_size\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfFhgVpMu5zX"
      },
      "source": [
        "Let's display patches for a sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "kOHP1MxVu5zX",
        "outputId": "ef487ec9-9742-4ea9-d740-eea4dfe6495c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: 32 X 32\n",
            "Patch size: 4 X 4\n",
            "Patches per image: 64\n",
            "Elements per patch: 48\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 64 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
        "plt.imshow(image.astype(\"uint8\"))\n",
        "plt.axis(\"off\")\n",
        "plt.savefig(\"original.png\", dpi=300, bbox_inches=\"tight\")\n",
        "\n",
        "resized_image = tf.image.resize(\n",
        "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
        ")\n",
        "patches = Patches(patch_size)(resized_image)\n",
        "print(f\"Image size: {image_size} X {image_size}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
        "\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
        "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")\n",
        "plt.savefig(\"patched.png\", dpi=300, bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jBkglq5u5zX"
      },
      "source": [
        "## Implement the patch encoding layer\n",
        "\n",
        "The `PatchEncoder` layer will linearly transform a patch by projecting it into a\n",
        "vector of size `projection_dim`. In addition, it adds a learnable position\n",
        "embedding to the projected vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CmG-dsffu5zX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "        \"num_patches\": self.num_patches,\n",
        "        \"projection\": self.projection,\n",
        "        \"position_embedding\": self.position_embedding,\n",
        "        })\n",
        "        return config\"\"\"\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim, **kwargs):\n",
        "        super(PatchEncoder, self).__init__(**kwargs)\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'num_patches': self.num_patches,\n",
        "            'projection_dim': self.projection.units  # 存儲投影維度而不是層對象\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7TQ-zu4u5zX"
      },
      "source": [
        "## Build the ViT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "k43gCKm3u5zY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f19ec34d-1fe4-44f6-8c9c-86180da9ba0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " data_augmentation (Sequent  (None, 32, 32, 3)            0         ['input_1[0][0]']             \n",
            " ial)                                                                                             \n",
            "                                                                                                  \n",
            " patches_1 (Patches)         (None, None, 48)             0         ['data_augmentation[0][0]']   \n",
            "                                                                                                  \n",
            " patch_encoder (PatchEncode  (None, 64, 48)               5424      ['patches_1[0][0]']           \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " layer_normalization (Layer  (None, 64, 48)               96        ['patch_encoder[0][0]']       \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention (Mult  (None, 64, 48)               18768     ['layer_normalization[0][0]', \n",
            " iHeadAttention)                                                     'layer_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 64, 48)               0         ['multi_head_attention[0][0]',\n",
            "                                                                     'patch_encoder[0][0]']       \n",
            "                                                                                                  \n",
            " layer_normalization_1 (Lay  (None, 64, 48)               96        ['add[0][0]']                 \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 64, 48)               2352      ['layer_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 64, 48)               0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 64, 48)               2352      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 64, 48)               0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 64, 48)               0         ['dropout_1[0][0]',           \n",
            "                                                                     'add[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, 64, 48)               96        ['add_1[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (Mu  (None, 64, 48)               18768     ['layer_normalization_2[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 64, 48)               0         ['multi_head_attention_1[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_1[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_3 (Lay  (None, 64, 48)               96        ['add_2[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 64, 48)               2352      ['layer_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 64, 48)               0         ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 64, 48)               2352      ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 64, 48)               0         ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 64, 48)               0         ['dropout_3[0][0]',           \n",
            "                                                                     'add_2[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_4 (Lay  (None, 64, 48)               96        ['add_3[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 3072)                 0         ['layer_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 3072)                 0         ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 192)                  590016    ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 192)                  0         ['dense_5[0][0]']             \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 96)                   18528     ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 96)                   0         ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 10)                   970       ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 662362 (2.53 MB)\n",
            "Trainable params: 662362 (2.53 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def create_vit_classifier():\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    augmented = data_augmentation(inputs)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(augmented)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.6)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    # Classify outputs.\n",
        "    logits = layers.Dense(num_classes)(features)\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model\n",
        "model=create_vit_classifier()\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbcoBmQsxHry",
        "outputId": "2544b8ae-cf47-44ec-af84-83219d6459ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.662362"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "create_vit_classifier().count_params()/1e6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZm_hg6uu5zY"
      },
      "source": [
        "## Compile, train, and evaluate the mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VIbGKt7u5zY",
        "outputId": "e84719be-3773-43d8-da6e-c117b79b5d41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "704/704 [==============================] - 17s 16ms/step - loss: 2.3235 - accuracy: 0.0992 - top-5-accuracy: 0.4926 - val_loss: 2.3031 - val_accuracy: 0.0986 - val_top-5-accuracy: 0.4928\n",
            "Epoch 2/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 2.3030 - accuracy: 0.0987 - top-5-accuracy: 0.4994 - val_loss: 2.3028 - val_accuracy: 0.0976 - val_top-5-accuracy: 0.4932\n",
            "Epoch 3/100\n",
            "704/704 [==============================] - 18s 25ms/step - loss: 2.3030 - accuracy: 0.0988 - top-5-accuracy: 0.4994 - val_loss: 2.3033 - val_accuracy: 0.0986 - val_top-5-accuracy: 0.4840\n",
            "Epoch 4/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 2.3032 - accuracy: 0.0975 - top-5-accuracy: 0.4937 - val_loss: 2.3029 - val_accuracy: 0.0976 - val_top-5-accuracy: 0.4898\n",
            "Epoch 5/100\n",
            "704/704 [==============================] - 11s 16ms/step - loss: 2.3029 - accuracy: 0.0990 - top-5-accuracy: 0.4972 - val_loss: 2.3030 - val_accuracy: 0.0986 - val_top-5-accuracy: 0.4994\n",
            "Epoch 6/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 2.3029 - accuracy: 0.1031 - top-5-accuracy: 0.5012 - val_loss: 2.3026 - val_accuracy: 0.0976 - val_top-5-accuracy: 0.5024\n",
            "Epoch 7/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 2.3032 - accuracy: 0.1028 - top-5-accuracy: 0.5009 - val_loss: 2.3029 - val_accuracy: 0.0958 - val_top-5-accuracy: 0.4908\n",
            "Epoch 8/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 2.1654 - accuracy: 0.1739 - top-5-accuracy: 0.6573 - val_loss: 1.8771 - val_accuracy: 0.3040 - val_top-5-accuracy: 0.8180\n",
            "Epoch 9/100\n",
            "704/704 [==============================] - 11s 15ms/step - loss: 1.8525 - accuracy: 0.3235 - top-5-accuracy: 0.8319 - val_loss: 1.6807 - val_accuracy: 0.3920 - val_top-5-accuracy: 0.8702\n",
            "Epoch 10/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 1.6986 - accuracy: 0.3826 - top-5-accuracy: 0.8745 - val_loss: 1.5369 - val_accuracy: 0.4486 - val_top-5-accuracy: 0.9136\n",
            "Epoch 11/100\n",
            "704/704 [==============================] - 10s 13ms/step - loss: 1.5930 - accuracy: 0.4232 - top-5-accuracy: 0.8977 - val_loss: 1.4619 - val_accuracy: 0.4746 - val_top-5-accuracy: 0.9284\n",
            "Epoch 12/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.5287 - accuracy: 0.4475 - top-5-accuracy: 0.9074 - val_loss: 1.3690 - val_accuracy: 0.5052 - val_top-5-accuracy: 0.9364\n",
            "Epoch 13/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.4832 - accuracy: 0.4635 - top-5-accuracy: 0.9169 - val_loss: 1.3501 - val_accuracy: 0.5246 - val_top-5-accuracy: 0.9402\n",
            "Epoch 14/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.4437 - accuracy: 0.4783 - top-5-accuracy: 0.9214 - val_loss: 1.3346 - val_accuracy: 0.5250 - val_top-5-accuracy: 0.9348\n",
            "Epoch 15/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 1.4162 - accuracy: 0.4928 - top-5-accuracy: 0.9244 - val_loss: 1.2580 - val_accuracy: 0.5514 - val_top-5-accuracy: 0.9474\n",
            "Epoch 16/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.3895 - accuracy: 0.5017 - top-5-accuracy: 0.9301 - val_loss: 1.2763 - val_accuracy: 0.5506 - val_top-5-accuracy: 0.9424\n",
            "Epoch 17/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.3670 - accuracy: 0.5106 - top-5-accuracy: 0.9330 - val_loss: 1.2337 - val_accuracy: 0.5528 - val_top-5-accuracy: 0.9504\n",
            "Epoch 18/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 1.3529 - accuracy: 0.5160 - top-5-accuracy: 0.9346 - val_loss: 1.1912 - val_accuracy: 0.5748 - val_top-5-accuracy: 0.9588\n",
            "Epoch 19/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.3286 - accuracy: 0.5283 - top-5-accuracy: 0.9367 - val_loss: 1.1547 - val_accuracy: 0.5916 - val_top-5-accuracy: 0.9604\n",
            "Epoch 20/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.3109 - accuracy: 0.5313 - top-5-accuracy: 0.9397 - val_loss: 1.1614 - val_accuracy: 0.5832 - val_top-5-accuracy: 0.9602\n",
            "Epoch 21/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.2962 - accuracy: 0.5403 - top-5-accuracy: 0.9409 - val_loss: 1.1352 - val_accuracy: 0.5928 - val_top-5-accuracy: 0.9624\n",
            "Epoch 22/100\n",
            "704/704 [==============================] - 10s 15ms/step - loss: 1.2784 - accuracy: 0.5475 - top-5-accuracy: 0.9435 - val_loss: 1.1174 - val_accuracy: 0.5948 - val_top-5-accuracy: 0.9634\n",
            "Epoch 23/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 1.2628 - accuracy: 0.5531 - top-5-accuracy: 0.9458 - val_loss: 1.1072 - val_accuracy: 0.6004 - val_top-5-accuracy: 0.9630\n",
            "Epoch 24/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.2567 - accuracy: 0.5528 - top-5-accuracy: 0.9457 - val_loss: 1.1196 - val_accuracy: 0.6056 - val_top-5-accuracy: 0.9624\n",
            "Epoch 25/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.2477 - accuracy: 0.5616 - top-5-accuracy: 0.9465 - val_loss: 1.0922 - val_accuracy: 0.6104 - val_top-5-accuracy: 0.9586\n",
            "Epoch 26/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.2360 - accuracy: 0.5650 - top-5-accuracy: 0.9491 - val_loss: 1.0817 - val_accuracy: 0.6246 - val_top-5-accuracy: 0.9640\n",
            "Epoch 27/100\n",
            "704/704 [==============================] - 9s 12ms/step - loss: 1.2259 - accuracy: 0.5681 - top-5-accuracy: 0.9482 - val_loss: 1.0945 - val_accuracy: 0.6142 - val_top-5-accuracy: 0.9654\n",
            "Epoch 28/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.2188 - accuracy: 0.5702 - top-5-accuracy: 0.9486 - val_loss: 1.0550 - val_accuracy: 0.6210 - val_top-5-accuracy: 0.9622\n",
            "Epoch 29/100\n",
            "704/704 [==============================] - 11s 16ms/step - loss: 1.2150 - accuracy: 0.5730 - top-5-accuracy: 0.9506 - val_loss: 1.0540 - val_accuracy: 0.6296 - val_top-5-accuracy: 0.9646\n",
            "Epoch 30/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.2043 - accuracy: 0.5772 - top-5-accuracy: 0.9517 - val_loss: 1.0326 - val_accuracy: 0.6332 - val_top-5-accuracy: 0.9696\n",
            "Epoch 31/100\n",
            "704/704 [==============================] - 9s 12ms/step - loss: 1.1964 - accuracy: 0.5776 - top-5-accuracy: 0.9513 - val_loss: 1.0289 - val_accuracy: 0.6340 - val_top-5-accuracy: 0.9656\n",
            "Epoch 32/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.1954 - accuracy: 0.5796 - top-5-accuracy: 0.9517 - val_loss: 1.0511 - val_accuracy: 0.6284 - val_top-5-accuracy: 0.9646\n",
            "Epoch 33/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.1768 - accuracy: 0.5883 - top-5-accuracy: 0.9526 - val_loss: 0.9986 - val_accuracy: 0.6440 - val_top-5-accuracy: 0.9700\n",
            "Epoch 34/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.1716 - accuracy: 0.5884 - top-5-accuracy: 0.9538 - val_loss: 0.9859 - val_accuracy: 0.6482 - val_top-5-accuracy: 0.9698\n",
            "Epoch 35/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 1.1718 - accuracy: 0.5892 - top-5-accuracy: 0.9538 - val_loss: 1.0057 - val_accuracy: 0.6522 - val_top-5-accuracy: 0.9724\n",
            "Epoch 36/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.1625 - accuracy: 0.5935 - top-5-accuracy: 0.9544 - val_loss: 1.0135 - val_accuracy: 0.6452 - val_top-5-accuracy: 0.9676\n",
            "Epoch 37/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.1547 - accuracy: 0.5944 - top-5-accuracy: 0.9554 - val_loss: 0.9855 - val_accuracy: 0.6554 - val_top-5-accuracy: 0.9722\n",
            "Epoch 38/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.1517 - accuracy: 0.5959 - top-5-accuracy: 0.9544 - val_loss: 1.0080 - val_accuracy: 0.6388 - val_top-5-accuracy: 0.9702\n",
            "Epoch 39/100\n",
            "704/704 [==============================] - 9s 12ms/step - loss: 1.1433 - accuracy: 0.5988 - top-5-accuracy: 0.9563 - val_loss: 1.0082 - val_accuracy: 0.6452 - val_top-5-accuracy: 0.9722\n",
            "Epoch 40/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.1408 - accuracy: 0.5989 - top-5-accuracy: 0.9573 - val_loss: 0.9852 - val_accuracy: 0.6466 - val_top-5-accuracy: 0.9732\n",
            "Epoch 41/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.1344 - accuracy: 0.6045 - top-5-accuracy: 0.9557 - val_loss: 0.9753 - val_accuracy: 0.6568 - val_top-5-accuracy: 0.9712\n",
            "Epoch 42/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 1.1274 - accuracy: 0.6060 - top-5-accuracy: 0.9579 - val_loss: 0.9913 - val_accuracy: 0.6430 - val_top-5-accuracy: 0.9730\n",
            "Epoch 43/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 1.1143 - accuracy: 0.6135 - top-5-accuracy: 0.9585 - val_loss: 0.9594 - val_accuracy: 0.6608 - val_top-5-accuracy: 0.9738\n",
            "Epoch 44/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.1166 - accuracy: 0.6098 - top-5-accuracy: 0.9580 - val_loss: 0.9589 - val_accuracy: 0.6636 - val_top-5-accuracy: 0.9750\n",
            "Epoch 45/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.1054 - accuracy: 0.6118 - top-5-accuracy: 0.9589 - val_loss: 0.9727 - val_accuracy: 0.6610 - val_top-5-accuracy: 0.9758\n",
            "Epoch 46/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.1094 - accuracy: 0.6151 - top-5-accuracy: 0.9589 - val_loss: 0.9481 - val_accuracy: 0.6744 - val_top-5-accuracy: 0.9724\n",
            "Epoch 47/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 1.0973 - accuracy: 0.6162 - top-5-accuracy: 0.9609 - val_loss: 0.9268 - val_accuracy: 0.6766 - val_top-5-accuracy: 0.9750\n",
            "Epoch 48/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0983 - accuracy: 0.6163 - top-5-accuracy: 0.9590 - val_loss: 0.9385 - val_accuracy: 0.6660 - val_top-5-accuracy: 0.9746\n",
            "Epoch 49/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0973 - accuracy: 0.6174 - top-5-accuracy: 0.9596 - val_loss: 0.9645 - val_accuracy: 0.6552 - val_top-5-accuracy: 0.9700\n",
            "Epoch 50/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0895 - accuracy: 0.6198 - top-5-accuracy: 0.9614 - val_loss: 0.9363 - val_accuracy: 0.6714 - val_top-5-accuracy: 0.9776\n",
            "Epoch 51/100\n",
            "704/704 [==============================] - 9s 12ms/step - loss: 1.0918 - accuracy: 0.6199 - top-5-accuracy: 0.9595 - val_loss: 0.9284 - val_accuracy: 0.6620 - val_top-5-accuracy: 0.9766\n",
            "Epoch 52/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0840 - accuracy: 0.6227 - top-5-accuracy: 0.9603 - val_loss: 0.9502 - val_accuracy: 0.6630 - val_top-5-accuracy: 0.9750\n",
            "Epoch 53/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0836 - accuracy: 0.6244 - top-5-accuracy: 0.9595 - val_loss: 0.9254 - val_accuracy: 0.6740 - val_top-5-accuracy: 0.9738\n",
            "Epoch 54/100\n",
            "704/704 [==============================] - 10s 15ms/step - loss: 1.0793 - accuracy: 0.6248 - top-5-accuracy: 0.9615 - val_loss: 0.9322 - val_accuracy: 0.6744 - val_top-5-accuracy: 0.9774\n",
            "Epoch 55/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 1.0759 - accuracy: 0.6281 - top-5-accuracy: 0.9609 - val_loss: 0.9337 - val_accuracy: 0.6730 - val_top-5-accuracy: 0.9762\n",
            "Epoch 56/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0748 - accuracy: 0.6250 - top-5-accuracy: 0.9606 - val_loss: 0.9152 - val_accuracy: 0.6788 - val_top-5-accuracy: 0.9792\n",
            "Epoch 57/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0737 - accuracy: 0.6290 - top-5-accuracy: 0.9605 - val_loss: 0.9055 - val_accuracy: 0.6772 - val_top-5-accuracy: 0.9738\n",
            "Epoch 58/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0701 - accuracy: 0.6299 - top-5-accuracy: 0.9625 - val_loss: 0.9369 - val_accuracy: 0.6596 - val_top-5-accuracy: 0.9732\n",
            "Epoch 59/100\n",
            "704/704 [==============================] - 9s 12ms/step - loss: 1.0599 - accuracy: 0.6307 - top-5-accuracy: 0.9619 - val_loss: 0.9459 - val_accuracy: 0.6656 - val_top-5-accuracy: 0.9758\n",
            "Epoch 60/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0678 - accuracy: 0.6290 - top-5-accuracy: 0.9616 - val_loss: 0.9180 - val_accuracy: 0.6708 - val_top-5-accuracy: 0.9792\n",
            "Epoch 61/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0526 - accuracy: 0.6371 - top-5-accuracy: 0.9644 - val_loss: 0.8889 - val_accuracy: 0.6856 - val_top-5-accuracy: 0.9772\n",
            "Epoch 62/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0638 - accuracy: 0.6317 - top-5-accuracy: 0.9615 - val_loss: 0.9364 - val_accuracy: 0.6634 - val_top-5-accuracy: 0.9762\n",
            "Epoch 63/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 1.0527 - accuracy: 0.6357 - top-5-accuracy: 0.9646 - val_loss: 0.8978 - val_accuracy: 0.6858 - val_top-5-accuracy: 0.9756\n",
            "Epoch 64/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0500 - accuracy: 0.6354 - top-5-accuracy: 0.9633 - val_loss: 0.8845 - val_accuracy: 0.6940 - val_top-5-accuracy: 0.9814\n",
            "Epoch 65/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0485 - accuracy: 0.6359 - top-5-accuracy: 0.9630 - val_loss: 0.9014 - val_accuracy: 0.6746 - val_top-5-accuracy: 0.9796\n",
            "Epoch 66/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0440 - accuracy: 0.6401 - top-5-accuracy: 0.9643 - val_loss: 0.8984 - val_accuracy: 0.6808 - val_top-5-accuracy: 0.9750\n",
            "Epoch 67/100\n",
            "704/704 [==============================] - 9s 12ms/step - loss: 1.0432 - accuracy: 0.6373 - top-5-accuracy: 0.9643 - val_loss: 0.9023 - val_accuracy: 0.6816 - val_top-5-accuracy: 0.9758\n",
            "Epoch 68/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0421 - accuracy: 0.6360 - top-5-accuracy: 0.9635 - val_loss: 0.8733 - val_accuracy: 0.6942 - val_top-5-accuracy: 0.9752\n",
            "Epoch 69/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0397 - accuracy: 0.6400 - top-5-accuracy: 0.9639 - val_loss: 0.8739 - val_accuracy: 0.6968 - val_top-5-accuracy: 0.9780\n",
            "Epoch 70/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0462 - accuracy: 0.6379 - top-5-accuracy: 0.9629 - val_loss: 0.8762 - val_accuracy: 0.6922 - val_top-5-accuracy: 0.9794\n",
            "Epoch 71/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 1.0373 - accuracy: 0.6405 - top-5-accuracy: 0.9644 - val_loss: 0.8602 - val_accuracy: 0.6968 - val_top-5-accuracy: 0.9780\n",
            "Epoch 72/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0358 - accuracy: 0.6423 - top-5-accuracy: 0.9641 - val_loss: 0.8757 - val_accuracy: 0.6948 - val_top-5-accuracy: 0.9790\n",
            "Epoch 73/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0301 - accuracy: 0.6429 - top-5-accuracy: 0.9648 - val_loss: 0.9036 - val_accuracy: 0.6812 - val_top-5-accuracy: 0.9768\n",
            "Epoch 74/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0303 - accuracy: 0.6427 - top-5-accuracy: 0.9637 - val_loss: 0.8910 - val_accuracy: 0.6876 - val_top-5-accuracy: 0.9760\n",
            "Epoch 75/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 1.0357 - accuracy: 0.6404 - top-5-accuracy: 0.9638 - val_loss: 0.8549 - val_accuracy: 0.6974 - val_top-5-accuracy: 0.9770\n",
            "Epoch 76/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0338 - accuracy: 0.6438 - top-5-accuracy: 0.9644 - val_loss: 0.8795 - val_accuracy: 0.6914 - val_top-5-accuracy: 0.9806\n",
            "Epoch 77/100\n",
            "704/704 [==============================] - 11s 16ms/step - loss: 1.0286 - accuracy: 0.6441 - top-5-accuracy: 0.9647 - val_loss: 0.8871 - val_accuracy: 0.6864 - val_top-5-accuracy: 0.9782\n",
            "Epoch 78/100\n",
            "704/704 [==============================] - 10s 15ms/step - loss: 1.0312 - accuracy: 0.6422 - top-5-accuracy: 0.9651 - val_loss: 0.8732 - val_accuracy: 0.6900 - val_top-5-accuracy: 0.9774\n",
            "Epoch 79/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 1.0267 - accuracy: 0.6463 - top-5-accuracy: 0.9654 - val_loss: 0.8835 - val_accuracy: 0.6922 - val_top-5-accuracy: 0.9748\n",
            "Epoch 80/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0266 - accuracy: 0.6459 - top-5-accuracy: 0.9648 - val_loss: 0.9469 - val_accuracy: 0.6698 - val_top-5-accuracy: 0.9720\n",
            "Epoch 81/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0242 - accuracy: 0.6478 - top-5-accuracy: 0.9650 - val_loss: 0.8667 - val_accuracy: 0.6918 - val_top-5-accuracy: 0.9824\n",
            "Epoch 82/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0241 - accuracy: 0.6438 - top-5-accuracy: 0.9657 - val_loss: 0.8950 - val_accuracy: 0.6840 - val_top-5-accuracy: 0.9738\n",
            "Epoch 83/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 1.0229 - accuracy: 0.6462 - top-5-accuracy: 0.9656 - val_loss: 0.8862 - val_accuracy: 0.6886 - val_top-5-accuracy: 0.9756\n",
            "Epoch 84/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0229 - accuracy: 0.6456 - top-5-accuracy: 0.9662 - val_loss: 0.8598 - val_accuracy: 0.6990 - val_top-5-accuracy: 0.9810\n",
            "Epoch 85/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0236 - accuracy: 0.6471 - top-5-accuracy: 0.9648 - val_loss: 0.8813 - val_accuracy: 0.6888 - val_top-5-accuracy: 0.9784\n",
            "Epoch 86/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0226 - accuracy: 0.6458 - top-5-accuracy: 0.9657 - val_loss: 0.8733 - val_accuracy: 0.6914 - val_top-5-accuracy: 0.9820\n",
            "Epoch 87/100\n",
            "704/704 [==============================] - 9s 13ms/step - loss: 1.0199 - accuracy: 0.6496 - top-5-accuracy: 0.9646 - val_loss: 0.8416 - val_accuracy: 0.7040 - val_top-5-accuracy: 0.9810\n",
            "Epoch 88/100\n",
            "704/704 [==============================] - 10s 14ms/step - loss: 1.0207 - accuracy: 0.6487 - top-5-accuracy: 0.9649 - val_loss: 0.8424 - val_accuracy: 0.7040 - val_top-5-accuracy: 0.9804\n",
            "Epoch 89/100\n",
            "446/704 [==================>...........] - ETA: 3s - loss: 1.0165 - accuracy: 0.6507 - top-5-accuracy: 0.9649"
          ]
        }
      ],
      "source": [
        "\n",
        "def run_experiment(model):\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"./tmp/checkpoint\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "vit_classifier = create_vit_classifier()\n",
        "history = run_experiment(vit_classifier)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPvTxOirxiPB"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train and Validation Losses Over Epochs\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n5pJ9V0mue1"
      },
      "outputs": [],
      "source": [
        "vit_classifier.save('my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoATjcwumue1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "custom_objects = {\n",
        "    'Patches': Patches,\n",
        "    'PatchEncoder': PatchEncoder  # 加入 PatchEncoder 類\n",
        "}\n",
        "loaded_model = load_model('my_model.h5', custom_objects=custom_objects)\n",
        "\n",
        "model.trainable_variables\n",
        "for var in model.trainable_variables:\n",
        "    print(f\"{var.name}: {var.shape}\")\n",
        "\n",
        "# 測試模型\n",
        "results = loaded_model.evaluate(x_test, y_test)\n",
        "print(\"Test accuracy:\", results[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw6JTR2mmue1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "environment": {
      "name": "tf2-gpu.2-4.m61",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m61"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}